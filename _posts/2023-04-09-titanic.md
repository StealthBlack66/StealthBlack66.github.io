---
layout: single
title: 타이타닉 경진대회 해결하기
date: 2023-04-09 10:44:00 +0900
---

안녕하세요. 오늘은 **캐글 타이타닉 경진대회** 문제를 해결해 보겠습니다.
타이타닉호의 침몰은 역사상 가장 악명 높은 난파선 중 하나입니다.

1912년 4월 15일, 타이타닉은 빙산과 충돌한 후 가라앉았습니다. 불행하게도, 탑승한 모든 사람들을 위한 구명보트가 충분하지 않았고, 2224명의 승객과 승무원 중 1502명이 사망했습니다.

생존에는 운이 따르는 요소가 있었지만, 일부 그룹의 사람들은 다른 그룹보다 생존할 가능성이 더 높은 것으로 보입니다.

이 과제에서는 다음과 같은 질문에 답할 수 있는 **예측 모델**을 구축할 것을 요청합니다:\
 승객 데이터(예: 이름, 나이, 성별, 사회 경제적 계층 등)를 사용하여\
**"어떤 종류의 사람들이 더 생존할 가능성이 높았습니까?"**


**기본 설정**

파이썬 3.7 이상을 요구한다.

    import sys

    assert sys.version_info >= (3, 7)

사이킷런 1.0.1 이상을 요구한다.

    import sklearn

    assert sklearn.__version__ >= "1.0.1"

다음은 이미지에 포함된 폰트 크기를 설정한다.

    import matplotlib.pyplot as plt

    plt.rc('font', size=14)
    plt.rc('axes', labelsize=14, titlesize=14)
    plt.rc('legend', fontsize=14)
    plt.rc('xtick', labelsize=10)
    plt.rc('ytick', labelsize=10)


# 3. 타이타닉 데이터셋 도전

승객의 나이, 성별, 승객 등급, 승선 위치 같은 속성을 기반으로 하여 승객의 생존 여부를 예측하는 것이 목표입니다.

먼저 캐글에 로그인 하고 타이타닉 챌린지에서 train.csv와 test.csv를 다운로드합니다. 두 파일을 datasets/titanic 디렉토리에 저장하세요(번역서 깃허브에는 두 파일이 이미 포함되어 있습니다).

데이터 적재:
---


    from sklearn.preprocessing import StandardScaler

    scaler = StandardScaler()

    from pathlib import Path
    import pandas as pd
    import tarfile
    import urllib.request

    def load_titanic_data():
        tarball_path = Path("datasets/titanic.tgz")
        if not tarball_path.is_file():
            Path("datasets").mkdir(parents=True, exist_ok=True)
            url = "https://github.com/ageron/data/raw/main/titanic.tgz"
            urllib.request.urlretrieve(url, tarball_path)
            with tarfile.open(tarball_path) as titanic_tarball:
                titanic_tarball.extractall(path="datasets")
        return [pd.read_csv(Path("datasets/titanic") / filename)
                for filename in ("train.csv", "test.csv")]

    train_data, test_data = load_titanic_data()

데이터는 이미 훈련 세트와 테스트 세트로 분리되어 있습니다. 그러나 테스트 데이터는 레이블을 가지고 있지 않습니다: 훈련 데이터를 이용하여 가능한 최고의 모델을 만들고 테스트 데이터에 대한 예측을 캐글(Kaggle)에 업로드하여 최종 점수를 확인하는 것이 목표입니다.

훈련 세트 살펴 보기:
---


    train_data.head()


속성:
---

*Survived: 타깃입니다. 0은 생존하지 못한 것이고 1은 생존을 의미합니다.\
*Pclass: 승객 등급. 1, 2, 3등석.\
*Name, Sex, Age: 이름 그대로 의미입니다.\
*SibSp: 함께 탑승한 형제, 배우자의 수.\
*Parch: 함께 탑승한 자녀, 부모의 수.\
*Ticket: 티켓 아이디\
*Fare: 티켓 요금 (파운드)\
*Cabin: 객실 번호\
*Embarked: 승객이 탑승한 곳. C(Cherbourg), Q(Queenstown), S(Southampton)\

누락된 데이터:
---

```
train_data = train_data.set_index("PassengerId")
test_data = test_data.set_index("PassengerId")

train_data.info()
```
```
output:
<class 'pandas.core.frame.DataFrame'>
Int64Index: 891 entries, 1 to 891
Data columns (total 11 columns):
 #   Column    Non-Null Count  Dtype  
---  ------    --------------  -----  
 0   Survived  891 non-null    int64  
 1   Pclass    891 non-null    int64  
 2   Name      891 non-null    object 
 3   Sex       891 non-null    object 
 4   Age       714 non-null    float64
 5   SibSp     891 non-null    int64  
 6   Parch     891 non-null    int64  
 7   Ticket    891 non-null    object 
 8   Fare      891 non-null    float64
 9   Cabin     204 non-null    object 
 10  Embarked  889 non-null    object 
dtypes: float64(2), int64(4), object(5)
memory usage: 83.5+ KB
```

    train_data[train_data["Sex"]=="female"]["Age"].median()
    output: 27.0

괜찮네요. Age, Cabin, Embarked 속성의 일부가 null입니다(891개의 non-null 보다 작습니다). 특히 Cabin은 77%가 null입니다. 일단 Cabin은 무시하고 나머지를 활용하겠습니다. Age는 19%가 null이므로 이를 어떻게 처리할지 결정해야 합니다. null을 중간 나이로 바꾸는 것이 괜찮아 보입니다.

Name과 Ticket 속성도 값을 가지고 있지만 머신러닝 모델이 사용할 수 있는 숫자로 변환하는 것이 조금 까다롭습니다. 그래서 지금은 이 두 속성을 무시하겠습니다.

통계치:
---

    train_data.describe()

* 이크, 38%만 Survived입니다. :( 거의 40%에 가까우므로 정확도를 사용해 모델을 평가해도 괜찮을 것 같습니다.
* 평균 Fare는 32.20 파운드라 그렇게 비싸보이지는 않습니다(아마 요금을 많이 반환해 주었기 때문일 것입니다)
* 평균 Age는 30보다 작습니다.\

타깃이 0과 1로 이루어졌는지 확인합니다:

범주형 특성 확인:
---

```
train_data["Survived"].value_counts()
output:
0    549
1    342
Name: Survived, dtype: int64
```

    train_data["Pclass"].value_counts()
    output:
    3    491
    1    216
    2    184
    Name: Pclass, dtype: int64

    train_data["Sex"].value_counts()
    output:
    male      577
    female    314
    Name: Sex, dtype: int64

    train_data["Embarked"].value_counts()
    output:
    S    644
    C    168
    Q     77
    Name: Embarked, dtype: int64

Embarked 특성은 승객이 탑승한 곳을 알려 줍니다: C=Cherbourg, Q=Queenstown, S=Southampton.

노트: 아래 코드는 Pipeline, FeatureUnion와 사용자 정의 DataFrameSelector 클래스를 사용해 각 열을 다르게 전처리합니다. 사이킷런 0.20부터는 이전 장에서처럼 ColumnTransformer를 사용하는 것이 좋습니다.

전처리 파이프라인 만들기. 
---
숫자 특성을 위한 파이프라인 만들기:


    from sklearn.pipeline import Pipeline
    from sklearn.impute import SimpleImputer

    num_pipeline = Pipeline([
            ("imputer", SimpleImputer(strategy="median")),
            ("scaler", StandardScaler())
        ])

이제 범주형 특성을 위한 파이프라인을 만듭니다:

    from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder

    cat_pipeline = Pipeline([
            ("ordinal_encoder", OrdinalEncoder()),    
            ("imputer", SimpleImputer(strategy="most_frequent")),
            ("cat_encoder", OneHotEncoder(sparse=False)),
        ])


최종 전처리 프파이프
---
이제 원본 데이터를 받아 머신러닝 모델에 주입할 숫자 입력 특성을 출력하는 전처리 파이프라인을 만들었습니다

    from sklearn.compose import ColumnTransformer

    num_attribs = ["Age", "SibSp", "Parch", "Fare"]
    cat_attribs = ["Pclass", "Sex", "Embarked"]

    preprocess_pipeline = ColumnTransformer([
            ("num", num_pipeline, num_attribs),
            ("cat", cat_pipeline, cat_attribs),
        ])
 


레이블 가져오기:
---
```

X_train = preprocess_pipeline.fit_transform(train_data)
X_train
output:
/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.
  warnings.warn(
array([[-0.56573582,  0.43279337, -0.47367361, ...,  0.        ,
         0.        ,  1.        ],
       [ 0.6638609 ,  0.43279337, -0.47367361, ...,  1.        ,
         0.        ,  0.        ],
       [-0.25833664, -0.4745452 , -0.47367361, ...,  0.        ,
         0.        ,  1.        ],
       ...,
       [-0.10463705,  0.43279337,  2.00893337, ...,  0.        ,
         0.        ,  1.        ],
       [-0.25833664, -0.4745452 , -0.47367361, ...,  1.        ,
         0.        ,  0.        ],
       [ 0.20276213, -0.4745452 , -0.47367361, ...,  0.        ,
         1.        ,  0.        ]])

```

    y_train = train_data["Survived"]

분류기를 훈련 
---
먼저 RandomForestClass를 사용해 보겠습니다:


    from sklearn.ensemble import RandomForestClassifier
    forest_clf = RandomForestClassifier(n_estimators=100, random_state=42)
    forest_clf.fit(X_train, y_train)

모델이 잘 훈련된 것 같습니다.

테스트 세트에 대한 예측 만들기:
---


    X_test = preprocess_pipeline.transform(test_data)
    y_pred = forest_clf.predict(X_test)

 이제 이러한 예측(Kaggle이 제외한 형식)을 사용하여 CSV 파일을 구축한 다음 업로드하여 최상의 결과를 기대할 수 있습니다.
 
 교차 검증
---
교차 검증을 사용하여 모델이 얼마나 우수한지 파악해 봅시다:


    from sklearn.model_selection import cross_val_score
    forest_scores = cross_val_score(forest_clf, X_train, y_train, cv=10)
    forest_scores.mean()
    output: 0.8137578027465668

좋아요, 나쁘지 않아요! 카글에 있는 타이타닉 대회의 리더보드를 보면, 우리 점수가 상위 2%에 있다는 것을 알 수 있습니다. 우후! 일부 카글러들은 100% 정확도에 도달했지만, 여러분은 타이타닉의 희생자 목록을 쉽게 찾을 수 있기 때문에, 그들의 수행에 기계 학습이 거의 관여하지 않은 것 같습니다!

SVC:
---


    from sklearn.svm import SVC

    svm_clf = SVC(gamma="auto")
    svm_scores = cross_val_score(svm_clf, X_train, y_train, cv=10)
    svm_scores.mean()
    output: 0.8249313358302123

10 폴드 교차 검증에 대한 평균 정확도를 보는 대신 모델에서 얻은 10개의 점수를 1사분위, 3사분위를 명료하게 표현해주는 상자 수염 그림(box-and-whisker) 그래프를 만들어 보겠습니다(이 방식을 제안해 준 Nevin Yilmaz에게 감사합니다). boxplot() 함수는 이상치(플라이어(flier)라고 부릅니다)를 감지하고 수염 부분에 이를 포함시키지 않습니다. 1사분위가 
$Q_1$이고 3사분위가 $Q_3$이라면 사분위수 범위는 $IQR = Q_3 - Q_1$가 됩니다(이 값이 박스의 높이가 됩니다). $Q_1 - 1.5 \times IQR$보다 낮거나 $Q3 + 1.5 \times IQR$보다 높은 점수는 이상치로 간주됩니다.

미세 조정
---


    plt.figure(figsize=(8, 4))
    plt.plot([1]*10, svm_scores, ".")
    plt.plot([2]*10, forest_scores, ".")
    plt.boxplot([svm_scores, forest_scores], labels=("SVM", "Random Forest"))
    plt.ylabel("Accuracy")
    plt.show()

이 결과를 더 향상시키려면:

* 교차 검증과 그리드 탐색을 사용하여 더 많은 모델을 비교하고 하이퍼파라미터를 튜닝하세요.
* 특성 공학을 더 시도해 보세요, 예를 들면:
    *    SibSp와 Parch을 이 두 특성의 합으로 바꿉니다.
    *    Survived 특성과 관련된 이름을 구별해 보세요(가령, 이름에 "Countess"가 있는 경우 생존할 가능성이 높습니다).
* 수치 특성을 범주형 특성으로 바꾸어 보세요: 예를 들어, 나이대가 다른 경우 다른 생존 비율을 가질 수 있습니다(아래 참조). 그러므로 나이 구간을 범주로 만들어 나이 대신 사용하는 것이 도움이 될 수 있스니다. 비슷하게 생존자의 30%가 혼자 여행하는 사람이기 때문에 이들을 위한 특별한 범주를 만드는 것이 도움이 될 수 있습니다(아래 참조).

---


    train_data["AgeBucket"] = train_data["Age"] // 15 * 15
    train_data[["AgeBucket", "Survived"]].groupby(['AgeBucket']).mean()

    train_data["RelativesOnboard"] = train_data["SibSp"] + train_data["Parch"]
    train_data[["RelativesOnboard", "Survived"]].groupby(
        ['RelativesOnboard']).mean()
